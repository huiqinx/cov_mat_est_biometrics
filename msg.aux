\relax 
\newlabel{firstpage}{{}{1}}
\citation{schafer2005shrinkage,markowetz2007inferring}
\citation{langfelder2008wgcna,zhang2005general}
\citation{rothman2009generalized,cai2011adaptive}
\citation{xue2012positive}
\citation{fan2008high}
\citation{li2017estimation}
\citation{liu2017covariance}
\citation{bun2016rotational,stein1975estimation,stein1986lectures}
\citation{ledoit2004well}
\citation{ledoit2012nonlinear,ledoit2019quadratic,lam2016nonparametric}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}\protected@file@percent }
\newlabel{introduction}{{1}{1}}
\citation{bun2016rotational}
\citation{mestre2008asymptotic}
\citation{robbins1951asymptotically}
\citation{jiang2009general,koenker2014convex,efron2019bayes}
\citation{dey2018corshrink}
\citation{robbins1951asymptotically}
\citation{johnstone2017gaussian}
\newlabel{sec:compound}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Covariance matrix estimation as a compound decision problem}{3}\protected@file@percent }
\newlabel{sec:background}{{2.1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Problem formulation}{3}\protected@file@percent }
\newlabel{frobenius risk}{{1}{3}}
\citation{james1961estimation}
\citation{james1961estimation}
\citation{brown2009nonparametric,jiang2009general,johnstone2017gaussian,lindley1962discussion,fourdrinier2018shrinkage}
\citation{cai2011adaptive}
\citation{donoho1995adapting}
\newlabel{eq:sigma}{{2}{4}}
\citation{ledoit2004well}
\citation{efron1973stein}
\citation{fourdrinier2018shrinkage,stigler19901988}
\newlabel{sec:connections}{{2.2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Reinterpretation of existing methods}{5}\protected@file@percent }
\newlabel{linear class}{{3}{5}}
\citation{ledoit2004well}
\citation{ledoit2004well}
\citation{biscarri2019thesis,lindley1962discussion,stigler19901988}
\citation{baranchik1964multiple}
\newlabel{prop:Rhat}{{1}{6}}
\newlabel{eq:Rhat}{{4}{6}}
\newlabel{eq:lw}{{5}{6}}
\newlabel{prop:linear}{{2}{6}}
\newlabel{eq:opt_linear}{{6}{6}}
\citation{brown2009nonparametric,jiang2009general,zhang2003compound}
\citation{robbins1951asymptotically}
\newlabel{sec:method}{{3}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{7}\protected@file@percent }
\newlabel{sec:class}{{3.1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}New class of estimators}{7}\protected@file@percent }
\newlabel{separable}{{7}{7}}
\citation{cai2011adaptive}
\citation{ledoit2004well}
\newlabel{sec:proposed}{{3.2}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Proposed estimator}{8}\protected@file@percent }
\citation{robbins1951asymptotically,zhang2003compound}
\citation{robbins1955empirical,zhang2003compound,brown2009nonparametric,jiang2009general,efron2014two,efron2019bayes}
\citation{efron2014two}
\citation{kiefer1956consistency}
\newlabel{eq:G}{{8}{9}}
\newlabel{prop:bayes risk}{{3}{9}}
\newlabel{eq:opt}{{9}{9}}
\newlabel{eq:tstar}{{10}{9}}
\newlabel{eq:f}{{11}{9}}
\citation{varin2011overview}
\citation{dey2018corshrink}
\citation{dey2018corshrink}
\citation{dey2018corshrink}
\newlabel{Gnd hat}{{12}{10}}
\newlabel{proposed}{{13}{10}}
\citation{lindsay1983geometry}
\citation{laird1978nonparametric}
\citation{jiang2009general,koenker2014convex,feng2018approximate}
\newlabel{implementation}{{3.3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Implementation}{11}\protected@file@percent }
\citation{saha2020nonparametric}
\citation{koenker2014convex}
\citation{higham1988computing}
\citation{huang2017calibration}
\citation{huang2017calibration}
\citation{huang2017calibration}
\newlabel{posdef}{{3.4}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Positive definiteness correction}{13}\protected@file@percent }
\newlabel{near posdef}{{14}{13}}
\newlabel{numerical results}{{4}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Numerical Results}{13}\protected@file@percent }
\newlabel{models}{{4.1}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Covariance matrix models}{13}\protected@file@percent }
\citation{cai2011adaptive}
\citation{dey2018corshrink}
\citation{lam2016nonparametric}
\citation{ledoit2019quadratic}
\citation{cai2011adaptive}
\citation{ledoit2004well}
\citation{ledoit2019quadratic}
\citation{lam2016nonparametric}
\citation{lam2016nonparametric}
\newlabel{compared}{{4.2}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Methods compared}{15}\protected@file@percent }
\citation{dey2018corshrink}
\citation{ledoit2019quadratic}
\newlabel{optimalK}{{4.3}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Clustering-based exemplar algorithm}{16}\protected@file@percent }
\newlabel{eq:sim_loss}{{15}{16}}
\citation{dey2018corshrink}
\newlabel{sec:accuracies}{{4.4}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Estimation accuracies}{17}\protected@file@percent }
\citation{markowetz2007inferring}
\citation{saul2017transcriptional}
\@writefile{toc}{\contentsline {section}{\numberline {5}Data analysis}{18}\protected@file@percent }
\newlabel{gene analysis}{{5}{18}}
\citation{cai2011adaptive}
\citation{cai2011adaptive}
\citation{jiang2009general}
\citation{saha2020nonparametric}
\newlabel{sec:discussion}{{6}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{20}\protected@file@percent }
\newlabel{discussion}{{6}{20}}
\bibstyle{biom}
\bibdata{biblio}
\bibcite{baranchik1964multiple}{{1}{1964}{{Baranchik}}{{Baranchik}}}
\bibcite{biscarri2019thesis}{{2}{2019}{{Biscarri}}{{Biscarri}}}
\bibcite{brown2009nonparametric}{{3}{2009}{{Brown and Greenshtein}}{{Brown and Greenshtein}}}
\bibcite{bun2016rotational}{{4}{2016}{{Bun et~al.}}{{Bun, Allez, Bouchaud, and Potters}}}
\@writefile{toc}{\contentsline {section}{References}{21}\protected@file@percent }
\bibcite{cai2011adaptive}{{5}{2011}{{Cai and Liu}}{{Cai and Liu}}}
\bibcite{dey2018corshrink}{{6}{2018}{{Dey and Stephens}}{{Dey and Stephens}}}
\bibcite{donoho1995adapting}{{7}{1995}{{Donoho and Johnstone}}{{Donoho and Johnstone}}}
\bibcite{efron2014two}{{8}{2014}{{Efron}}{{Efron}}}
\bibcite{efron2019bayes}{{9}{2019}{{Efron}}{{Efron}}}
\bibcite{efron1973stein}{{10}{1973}{{Efron and Morris}}{{Efron and Morris}}}
\bibcite{fan2008high}{{11}{2008}{{Fan et~al.}}{{Fan, Fan, and Lv}}}
\bibcite{feng2018approximate}{{12}{2018}{{Feng and Dicker}}{{Feng and Dicker}}}
\bibcite{fourdrinier2018shrinkage}{{13}{2018}{{Fourdrinier et~al.}}{{Fourdrinier, Strawderman, and Wells}}}
\bibcite{higham1988computing}{{14}{1988}{{Higham}}{{Higham}}}
\bibcite{huang2017calibration}{{15}{2017}{{Huang et~al.}}{{Huang, Farewell, and Pan}}}
\bibcite{james1961estimation}{{16}{1961}{{James and Stein}}{{James and Stein}}}
\bibcite{jiang2009general}{{17}{2009}{{Jiang and Zhang}}{{Jiang and Zhang}}}
\bibcite{johnstone2017gaussian}{{18}{2017}{{Johnstone}}{{Johnstone}}}
\bibcite{kiefer1956consistency}{{19}{1956}{{Kiefer and Wolfowitz}}{{Kiefer and Wolfowitz}}}
\bibcite{koenker2014convex}{{20}{2014}{{Koenker and Mizera}}{{Koenker and Mizera}}}
\bibcite{laird1978nonparametric}{{21}{1978}{{Laird}}{{Laird}}}
\bibcite{lam2016nonparametric}{{22}{2016}{{Lam et~al.}}{{Lam et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{langfelder2008wgcna}{{23}{2008}{{Langfelder and Horvath}}{{Langfelder and Horvath}}}
\bibcite{ledoit2004well}{{24}{2004}{{Ledoit and Wolf}}{{Ledoit and Wolf}}}
\bibcite{ledoit2019quadratic}{{25}{2019}{{Ledoit and Wolf}}{{Ledoit and Wolf}}}
\bibcite{ledoit2012nonlinear}{{26}{2012}{{Ledoit et~al.}}{{Ledoit, Wolf, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{li2017estimation}{{27}{2017}{{Li et~al.}}{{Li, Zhou, Zhang, and Li}}}
\bibcite{lindley1962discussion}{{28}{1962}{{Lindley}}{{Lindley}}}
\bibcite{lindsay1983geometry}{{29}{1983}{{Lindsay}}{{Lindsay}}}
\bibcite{liu2017covariance}{{30}{2017}{{Liu et~al.}}{{Liu, Sun, and Zhao}}}
\bibcite{markowetz2007inferring}{{31}{2007}{{Markowetz and Spang}}{{Markowetz and Spang}}}
\bibcite{mestre2008asymptotic}{{32}{2008}{{Mestre}}{{Mestre}}}
\bibcite{robbins1951asymptotically}{{33}{1951}{{Robbins}}{{Robbins}}}
\bibcite{robbins1955empirical}{{34}{1955}{{Robbins}}{{Robbins}}}
\bibcite{rothman2009generalized}{{35}{2009}{{Rothman et~al.}}{{Rothman, Levina, and Zhu}}}
\bibcite{saha2020nonparametric}{{36}{2020}{{Saha et~al.}}{{Saha, Guntuboyina, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{saul2017transcriptional}{{37}{2017}{{Saul et~al.}}{{Saul, Seward, Troy, Zhang, Sloofman, Lu, Weisner, Caetano-Anolles, Sun, Zhao, Chandrasekaran, Sinha, and Stubbs}}}
\bibcite{schafer2005shrinkage}{{38}{2005}{{Sch{\"a}fer and Strimmer}}{{Sch{\"a}fer and Strimmer}}}
\bibcite{stein1975estimation}{{39}{1975}{{Stein}}{{Stein}}}
\bibcite{stein1986lectures}{{40}{1986}{{Stein}}{{Stein}}}
\bibcite{stigler19901988}{{41}{1990}{{Stigler}}{{Stigler}}}
\bibcite{varin2011overview}{{42}{2011}{{Varin et~al.}}{{Varin, Reid, and Firth}}}
\bibcite{xue2012positive}{{43}{2012}{{Xue et~al.}}{{Xue, Ma, and Zou}}}
\bibcite{zhang2005general}{{44}{2005}{{Zhang and Horvath}}{{Zhang and Horvath}}}
\bibcite{zhang2003compound}{{45}{2003}{{Zhang}}{{Zhang}}}
\@writefile{toc}{\contentsline {section}{}{26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Proof of Proposition 1\hbox {}}{26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Proof of Proposition 2\hbox {}}{26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Proof of Proposition 3\hbox {}}{28}\protected@file@percent }
\newlabel{lastpage}{{6}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Median Frobenius norm errors over 200 replications for our proposed MSGCor. Exact numerical results and interquartile ranges are provided in the Supporting Information. Sparse: Model 1; Hypercorrelated: Model 2; Dense-0.7: Model 3; Dense-0.9: Model 4; Orthogonal: Model 5; Spiked: Model 6.}}{29}\protected@file@percent }
\newlabel{fig:sim1_frobenius}{{1}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Median Frobenius norm errors over 200 replications. Exact numerical results and interquartile ranges are provided in the Supporting Information. MSG and MSGCor were implemented with $K = p$. Sparse: Model 1; Hypercorrelated: Model 2; Dense-0.7: Model 3; Dense-0.9: Model 4; Orthogonal: Model 5; Spiked: Model 6.}}{30}\protected@file@percent }
\newlabel{fig:sim2_frobenius}{{2}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Estimation errors of sample eigenvectors over 200 replications. Sparse: Model 1; Hypercorrelated: Model 2; Dense-0.7: Model 3; Dense-0.9: Model 4; Orthogonal: Model 5; Spiked: Model 6.}}{31}\protected@file@percent }
\newlabel{fig:eigenvectors}{{3}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Amygdala gene networks recovered by the different covariance matrix estimation methods.}}{32}\protected@file@percent }
\newlabel{network_A}{{4}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Frontal cortex gene networks recovered by the different covariance matrix estimation methods.}}{33}\protected@file@percent }
\newlabel{network_FC}{{5}{33}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Average running time of MSGCor under Model 1 for different $K$.}}{34}\protected@file@percent }
\newlabel{tab:sim1_time}{{1}{34}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Median gene expression covariance matrix estimation errors (25\% and 75\% quantiles in parentheses). Bold text highlights the smallest median errors in each column.}}{35}\protected@file@percent }
\newlabel{tab:tab1}{{2}{35}}
