\relax 
\newlabel{firstpage}{{}{1}}
\citation{ledoit2003improved}
\citation{schafer2005shrinkage}
\citation{abramovich2001locally}
\citation{rothman2009generalized,cai2011adaptive}
\citation{xue2012positive}
\citation{fan2008high}
\citation{li2017estimation}
\citation{liu2017covariance}
\citation{ledoit2004well}
\citation{ledoit2012nonlinear,ledoit2019quadratic,lam2016nonparametric}
\citation{ledoit2018analytical}
\citation{stein1975estimation,stein1986lectures}
\citation{mestre2008asymptotic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}\protected@file@percent }
\newlabel{introduction}{{1}{1}}
\citation{jiang2009general,koenker2014convex}
\citation{dey2018corshrink}
\citation{robbins1951asymptotically}
\citation{johnstone2017gaussian}
\citation{james1961estimation}
\citation{brown2009nonparametric,jiang2009general,johnstone2017gaussian,lindley1962discussion,fourdrinier2018shrinkage}
\newlabel{sec:method}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{3}\protected@file@percent }
\newlabel{sec:compound}{{2.1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Compound decision problem formulation}{3}\protected@file@percent }
\newlabel{frobenius risk}{{1}{3}}
\newlabel{compound risk}{{2}{3}}
\citation{cai2011adaptive}
\citation{donoho1995adapting}
\citation{ledoit2004well}
\newlabel{linear model}{{3}{4}}
\newlabel{linear class}{{4}{4}}
\citation{biscarri2019thesis,lindley1962discussion}
\citation{ledoit2004well}
\citation{robbins1951asymptotically}
\newlabel{prop:linear}{{1}{5}}
\newlabel{sec:proposed}{{2.2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Proposed estimator}{5}\protected@file@percent }
\newlabel{separable}{{5}{5}}
\citation{ledoit2004well}
\citation{cai2011adaptive}
\citation{zhang2003compound}
\citation{robbins1955empirical,zhang2003compound,brown2009nonparametric,jiang2009general,efron2014two,efron2019bayes}
\citation{robbins1951asymptotically,jiang2009general}
\citation{kiefer1956consistency}
\newlabel{bayesian nondiagonal}{{6}{7}}
\newlabel{bayesian diagonal}{{7}{7}}
\newlabel{eq:marginal}{{8}{7}}
\newlabel{prop:bayes risk}{{2}{7}}
\citation{varin2011overview}
\citation{efron2014two}
\citation{dey2018corshrink}
\citation{ledoit2004well}
\citation{lindsay1983geometry}
\citation{laird1978nonparametric}
\newlabel{Gnd hat}{{9}{8}}
\newlabel{proposed}{{10}{8}}
\newlabel{implementation}{{2.3}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Implementation}{8}\protected@file@percent }
\citation{jiang2009general,koenker2014convex,feng2018approximate}
\citation{koenker2019comment}
\citation{koenker2014convex}
\citation{saha2020nonparametric}
\newlabel{eq:iteration}{{11}{9}}
\citation{higham1988computing}
\citation{huang2017calibration}
\citation{huang2017calibration}
\citation{huang2017calibration}
\newlabel{posdef}{{2.4}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Positive definiteness correction}{10}\protected@file@percent }
\newlabel{near posdef}{{13}{10}}
\citation{cai2011adaptive}
\newlabel{numerical results}{{3}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Numerical Results}{11}\protected@file@percent }
\newlabel{models}{{3.1}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Models}{11}\protected@file@percent }
\citation{lam2016nonparametric}
\citation{ledoit2019quadratic}
\newlabel{optimalK}{{3.2}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Clustering-based exemplar algorithm}{12}\protected@file@percent }
\citation{ledoit2004well}
\citation{ledoit2019quadratic}
\citation{lam2016nonparametric}
\citation{cai2011adaptive}
\citation{dey2018corshrink}
\newlabel{compared}{{3.3}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Methods compared}{13}\protected@file@percent }
\citation{ledoit2019quadratic}
\citation{ledoit2004well}
\citation{markowetz2007inferring}
\citation{khan2001classification}
\citation{cai2011adaptive}
\citation{osareh2009classification}
\citation{cai2011adaptive}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Data analysis}{15}\protected@file@percent }
\newlabel{gene analysis}{{3.4}{15}}
\citation{cai2011adaptive}
\citation{cai2011adaptive}
\citation{jiang2009general}
\citation{saha2020nonparametric}
\newlabel{sec:discussion}{{4}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{17}\protected@file@percent }
\newlabel{discussion}{{4}{17}}
\bibstyle{biom}
\bibdata{biblio}
\bibcite{abramovich2001locally}{{1}{2001}{{Abramovich et~al.}}{{Abramovich, Spencer, and Gorokhov}}}
\bibcite{biscarri2019thesis}{{2}{2019}{{Biscarri}}{{Biscarri}}}
\bibcite{brown2009nonparametric}{{3}{2009}{{Brown and Greenshtein}}{{Brown and Greenshtein}}}
\@writefile{toc}{\contentsline {section}{References}{18}\protected@file@percent }
\bibcite{cai2011adaptive}{{4}{2011}{{Cai and Liu}}{{Cai and Liu}}}
\bibcite{dey2018corshrink}{{5}{2018}{{Dey and Stephens}}{{Dey and Stephens}}}
\bibcite{donoho1995adapting}{{6}{1995}{{Donoho and Johnstone}}{{Donoho and Johnstone}}}
\bibcite{efron2014two}{{7}{2014}{{Efron}}{{Efron}}}
\bibcite{efron2019bayes}{{8}{2019}{{Efron}}{{Efron}}}
\bibcite{fan2008high}{{9}{2008}{{Fan et~al.}}{{Fan, Fan, and Lv}}}
\bibcite{feng2018approximate}{{10}{2018}{{Feng and Dicker}}{{Feng and Dicker}}}
\bibcite{fourdrinier2018shrinkage}{{11}{2018}{{Fourdrinier et~al.}}{{Fourdrinier, Strawderman, and Wells}}}
\bibcite{higham1988computing}{{12}{1988}{{Higham}}{{Higham}}}
\bibcite{huang2017calibration}{{13}{2017}{{Huang et~al.}}{{Huang, Farewell, and Pan}}}
\bibcite{james1961estimation}{{14}{1961}{{James and Stein}}{{James and Stein}}}
\bibcite{jiang2009general}{{15}{2009}{{Jiang and Zhang}}{{Jiang and Zhang}}}
\bibcite{johnstone2017gaussian}{{16}{2017}{{Johnstone}}{{Johnstone}}}
\bibcite{khan2001classification}{{17}{2001}{{Khan et~al.}}{{Khan, Wei, Ringner, Saal, Ladanyi, Westermann, Berthold, Schwab, Antonescu, Peterson, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{kiefer1956consistency}{{18}{1956}{{Kiefer and Wolfowitz}}{{Kiefer and Wolfowitz}}}
\bibcite{koenker2019comment}{{19}{2019}{{Koenker et~al.}}{{Koenker, Gu, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{koenker2014convex}{{20}{2014}{{Koenker and Mizera}}{{Koenker and Mizera}}}
\bibcite{laird1978nonparametric}{{21}{1978}{{Laird}}{{Laird}}}
\bibcite{lam2016nonparametric}{{22}{2016}{{Lam et~al.}}{{Lam et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{ledoit2003improved}{{23}{2003}{{Ledoit and Wolf}}{{Ledoit and Wolf}}}
\bibcite{ledoit2018analytical}{{24}{2018}{{Ledoit and Wolf}}{{Ledoit and Wolf}}}
\bibcite{ledoit2019quadratic}{{25}{2019}{{Ledoit and Wolf}}{{Ledoit and Wolf}}}
\bibcite{ledoit2004well}{{26}{2004}{{Ledoit et~al.}}{{Ledoit, Wolf, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{ledoit2012nonlinear}{{27}{2012}{{Ledoit et~al.}}{{Ledoit, Wolf, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{li2017estimation}{{28}{2017}{{Li et~al.}}{{Li, Zhou, Zhang, and Li}}}
\bibcite{lindley1962discussion}{{29}{1962}{{Lindley}}{{Lindley}}}
\bibcite{lindsay1983geometry}{{30}{1983}{{Lindsay}}{{Lindsay}}}
\bibcite{liu2017covariance}{{31}{2017}{{Liu et~al.}}{{Liu, Sun, and Zhao}}}
\bibcite{markowetz2007inferring}{{32}{2007}{{Markowetz and Spang}}{{Markowetz and Spang}}}
\bibcite{mestre2008asymptotic}{{33}{2008}{{Mestre}}{{Mestre}}}
\bibcite{osareh2009classification}{{34}{2009}{{Osareh and Shadgar}}{{Osareh and Shadgar}}}
\bibcite{robbins1951asymptotically}{{35}{1951}{{Robbins}}{{Robbins}}}
\bibcite{robbins1955empirical}{{36}{1955}{{Robbins}}{{Robbins}}}
\bibcite{rothman2009generalized}{{37}{2009}{{Rothman et~al.}}{{Rothman, Levina, and Zhu}}}
\bibcite{saha2020nonparametric}{{38}{2020}{{Saha et~al.}}{{Saha, Guntuboyina, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{schafer2005shrinkage}{{39}{2005}{{Sch{\"a}fer and Strimmer}}{{Sch{\"a}fer and Strimmer}}}
\bibcite{stein1975estimation}{{40}{1975}{{Stein}}{{Stein}}}
\bibcite{stein1986lectures}{{41}{1986}{{Stein}}{{Stein}}}
\bibcite{varin2011overview}{{42}{2011}{{Varin et~al.}}{{Varin, Reid, and Firth}}}
\bibcite{xue2012positive}{{43}{2012}{{Xue et~al.}}{{Xue, Ma, and Zou}}}
\bibcite{zhang2003compound}{{44}{2003}{{Zhang}}{{Zhang}}}
\citation{ledoit2004well}
\@writefile{toc}{\contentsline {section}{}{23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Proof of Proposition \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 1\hbox {}\unskip \@@italiccorr )}}}{23}\protected@file@percent }
\newlabel{eq:lw}{{A.1}{23}}
\@writefile{toc}{\contentsline {subsection}{Proof of Proposition \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 2\hbox {}\unskip \@@italiccorr )}}}{25}\protected@file@percent }
\newlabel{lastpage}{{4}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Average Frobenius norm errors over 200 replications. The Sparse, Block, Dense, Dense2, Orth and Spiked panels correspond to Models 1 through 5, respectively.}}{26}\protected@file@percent }
\newlabel{fig:sim1_frobenius}{{1}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Average Frobenius norm errors over 200 replications. The Sparse, Block, Dense, Dense2, and Orth panels correspond to Models 1 through 5, respectively. In MSG, $K$-means clustering is applied with $K=p$}}{27}\protected@file@percent }
\newlabel{fig:sim2_frobenius}{{2}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Gene networks recovered by the different covariance matrix estimation methods.}}{28}\protected@file@percent }
\newlabel{network}{{3}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Similarities of gene degrees between the estimated networks. Each number reports the Jaccard index between the top 20\% most connected genes of each pair of networks.}}{29}\protected@file@percent }
\newlabel{top20}{{4}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Average running time for different ratios.}}{30}\protected@file@percent }
\newlabel{tab:sim1_time}{{1}{30}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Average gene expression covariance matrix estimation errors. Bold entries highlight the smallest errors in each column.}}{31}\protected@file@percent }
\newlabel{tab:tab1}{{2}{31}}
