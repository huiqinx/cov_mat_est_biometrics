\relax 
\newlabel{firstpage}{{}{1}}
\citation{ledoit2003improved}
\citation{schafer2005shrinkage}
\citation{abramovich2001locally}
\citation{rothman2009generalized,cai2011adaptive}
\citation{xue2012positive}
\citation{fan2008high}
\citation{li2017estimation}
\citation{liu2017covariance}
\citation{ledoit2004well}
\citation{ledoit2012nonlinear,ledoit2019quadratic,lam2016nonparametric}
\citation{ledoit2018analytical}
\citation{mestre2008asymptotic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}\protected@file@percent }
\newlabel{introduction}{{1}{1}}
\citation{jiang2009general,koenker2014convex}
\newlabel{sec:method}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{2}\protected@file@percent }
\newlabel{sec:compound}{{2.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Compound decision problem formulation}{2}\protected@file@percent }
\newlabel{frobenius risk}{{1}{2}}
\citation{robbins1951asymptotically}
\citation{johnstone2017gaussian}
\citation{james1961estimation}
\citation{brown2009nonparametric,jiang2009general,johnstone2017gaussian,lindley1962discussion,fourdrinier2018shrinkage}
\citation{cai2011adaptive}
\citation{donoho1995adapting}
\newlabel{compound risk}{{2}{3}}
\citation{ledoit2004well}
\citation{biscarri2019thesis,lindley1962discussion}
\citation{ledoit2004well}
\citation{robbins1951asymptotically}
\newlabel{linear model}{{3}{4}}
\newlabel{linear class}{{4}{4}}
\newlabel{prop:linear}{{1}{4}}
\citation{ledoit2004well}
\citation{cai2011adaptive}
\citation{zhang2003compound}
\citation{robbins1955empirical,zhang2003compound,brown2009nonparametric,jiang2009general,efron2014two,efron2019bayes}
\newlabel{sec:proposed}{{2.2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Proposed estimator}{5}\protected@file@percent }
\newlabel{separable}{{5}{5}}
\citation{robbins1951asymptotically,jiang2009general}
\citation{kiefer1956consistency}
\newlabel{bayesian nondiagonal}{{6}{6}}
\newlabel{bayesian diagonal}{{7}{6}}
\citation{varin2011overview}
\citation{efron2014two}
\citation{ledoit2004well}
\citation{lindsay1983geometry}
\citation{laird1978nonparametric}
\citation{jiang2009general,koenker2014convex,feng2018approximate}
\newlabel{Gnd hat}{{8}{7}}
\newlabel{Gd hat}{{9}{7}}
\newlabel{proposed}{{10}{7}}
\newlabel{implementation}{{2.3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Implementation}{7}\protected@file@percent }
\citation{koenker2019comment}
\citation{koenker2014convex}
\citation{saha2020nonparametric}
\citation{higham1988computing}
\citation{huang2017calibration}
\citation{huang2017calibration}
\citation{huang2017calibration}
\citation{cai2011adaptive}
\newlabel{posdef}{{2.4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Positive definiteness correction}{9}\protected@file@percent }
\newlabel{near posdef}{{12}{9}}
\newlabel{numerical results}{{3}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Numerical Results}{9}\protected@file@percent }
\newlabel{models}{{3.1}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Models}{9}\protected@file@percent }
\citation{lam2016nonparametric}
\citation{ledoit2019quadratic}
\citation{ledoit2004well}
\citation{ledoit2019quadratic}
\newlabel{optimalK}{{3.2}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Clustering-based exemplar algorithm}{11}\protected@file@percent }
\newlabel{compared}{{3.3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Methods compared}{11}\protected@file@percent }
\citation{lam2016nonparametric}
\citation{cai2011adaptive}
\citation{ledoit2019quadratic}
\citation{ledoit2004well}
\citation{cai2011adaptive}
\citation{markowetz2007inferring}
\citation{khan2001classification}
\citation{cai2011adaptive}
\citation{osareh2009classification}
\citation{cai2011adaptive}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Data analysis}{13}\protected@file@percent }
\newlabel{gene analysis}{{3.4}{13}}
\citation{cai2011adaptive}
\citation{cai2011adaptive}
\citation{jiang2009general}
\citation{saha2020nonparametric}
\bibstyle{biom}
\bibdata{biblio}
\newlabel{sec:discussion}{{4}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{16}\protected@file@percent }
\newlabel{discussion}{{4}{16}}
\@writefile{toc}{\contentsline {section}{}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Proof of Proposition 1\hbox {}}{17}\protected@file@percent }
\newlabel{lastpage}{{4}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Average Frobenius norm errors over 200 replications. The Sparse, Block, Dense, Dense2, and Orth panels correspond to Models 1 through 5, respectively.}}{19}\protected@file@percent }
\newlabel{fig:sim1_frobenius}{{1}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Average Frobenius norm errors over 200 replications. The Sparse, Block, Dense, Dense2, and Orth panels correspond to Models 1 through 5, respectively. In MSG, $K$-means clustering is applied with $K=p$}}{20}\protected@file@percent }
\newlabel{fig:sim2_frobenius}{{2}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Gene networks recovered by the different covariance matrix estimation methods.}}{21}\protected@file@percent }
\newlabel{network}{{3}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Similarities of gene degrees between the estimated networks. Each number reports the Jaccard index between the top 20\% most connected genes of each pair of networks.}}{22}\protected@file@percent }
\newlabel{top20}{{4}{22}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Average running time for different ratios.}}{23}\protected@file@percent }
\newlabel{tab:sim1_time}{{1}{23}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Average gene expression covariance matrix estimation errors. Bold entries highlight the smallest errors in each column.}}{24}\protected@file@percent }
\newlabel{tab:tab1}{{2}{24}}
